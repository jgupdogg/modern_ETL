#!/usr/bin/env python3
"""
Quick Duplicate Check

Uses boto3 to download and analyze a sample of parquet files
to check for duplicates without relying on DuckDB S3 connection.

Author: Generated by Claude Code
Date: 2025-06-19
"""

import boto3
import pandas as pd
import pyarrow.parquet as pq
import io
from collections import defaultdict

def main():
    # MinIO client
    s3_client = boto3.client(
        's3',
        endpoint_url='http://localhost:9000',
        aws_access_key_id='minioadmin',
        aws_secret_access_key='minioadmin123',
        region_name='us-east-1'
    )
    
    bucket = 'solana-data'
    prefix = 'bronze/wallet_trade_history_bronze_fixed/'
    
    print("\n" + "="*60)
    print("QUICK DUPLICATE CHECK")
    print("="*60)
    
    # Sample a few files to check for duplicates
    try:
        response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix, MaxKeys=10)
        
        if 'Contents' not in response:
            print("‚ùå No files found")
            return
        
        total_records = 0
        unique_pairs = set()
        duplicate_examples = []
        
        print(f"üìÅ Sampling {len(response['Contents'])} files...")
        
        for obj in response['Contents'][:5]:  # Check first 5 files
            key = obj['Key']
            print(f"  Reading: {key}")
            
            try:
                # Download and read parquet file
                response = s3_client.get_object(Bucket=bucket, Key=key)
                parquet_buffer = io.BytesIO(response['Body'].read())
                
                # Read with pyarrow
                table = pq.read_table(parquet_buffer)
                df = table.to_pandas()
                
                # Check for duplicates in this file
                for _, row in df.iterrows():
                    total_records += 1
                    pair = (row['wallet_address'], row['transaction_hash'])
                    
                    if pair in unique_pairs:
                        duplicate_examples.append({
                            'wallet': row['wallet_address'][:12] + "...",
                            'tx_hash': row['transaction_hash'][:12] + "...",
                            'timestamp': row['timestamp'],
                            'file': key
                        })
                    else:
                        unique_pairs.add(pair)
                
            except Exception as e:
                print(f"    ‚ùå Error reading {key}: {e}")
                continue
        
        print(f"\nüìä SAMPLE ANALYSIS:")
        print(f"  Records Analyzed: {total_records:,}")
        print(f"  Unique (Wallet, TxHash) Pairs: {len(unique_pairs):,}")
        print(f"  Potential Duplicates Found: {len(duplicate_examples):,}")
        
        if duplicate_examples:
            print(f"\n‚ö†Ô∏è  DUPLICATE EXAMPLES:")
            for dup in duplicate_examples[:3]:
                print(f"  {dup['wallet']} | {dup['tx_hash']} | {dup['timestamp']}")
            print(f"\nüîß RECOMMENDATION: Run full deduplication")
        else:
            print(f"\n‚úÖ NO DUPLICATES IN SAMPLE")
            print(f"  Sample appears clean, but full check recommended")
            
    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    main()