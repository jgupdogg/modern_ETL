#!/usr/bin/env python3
"""
PostgreSQL Wallet Trade History Schema Analysis

Connects to the solana database and analyzes the wallet_trade_history table
to understand its structure before migration.

Author: Generated by Claude Code
Date: 2025-06-19
"""

import os
import logging
import psycopg2
import pandas as pd
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class WalletTradeHistoryAnalyzer:
    """Analyzes wallet_trade_history table schema and data"""
    
    def __init__(self):
        """Initialize PostgreSQL connection using same config as existing migration script"""
        
        # PostgreSQL connection - updated for solana database
        self.pg_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': int(os.getenv('DB_PORT', 5432)),
            'database': 'solana',  # Updated database name
            'user': os.getenv('DB_USER', 'postgres'),
            'password': os.getenv('DB_PASSWORD', 'St0ck!adePG')
        }
        
        self.table_name = 'wallet_trade_history'
        self.schema_name = 'public'
        
    def test_connection(self):
        """Test PostgreSQL connection"""
        try:
            with psycopg2.connect(**self.pg_config) as conn:
                with conn.cursor() as cur:
                    cur.execute("SELECT version();")
                    version = cur.fetchone()[0]
                    logger.info(f"‚úÖ Connected to PostgreSQL: {version}")
                    
                    # Check if database exists and we can access it
                    cur.execute("SELECT current_database();")
                    db_name = cur.fetchone()[0]
                    logger.info(f"‚úÖ Connected to database: {db_name}")
                    
                    return True
        except Exception as e:
            logger.error(f"‚ùå Connection failed: {e}")
            return False
    
    def analyze_table_schema(self):
        """Analyze the wallet_trade_history table schema"""
        try:
            with psycopg2.connect(**self.pg_config) as conn:
                # Get table schema information
                schema_query = """
                SELECT 
                    column_name,
                    data_type,
                    character_maximum_length,
                    is_nullable,
                    column_default,
                    ordinal_position
                FROM information_schema.columns 
                WHERE table_schema = %s AND table_name = %s
                ORDER BY ordinal_position;
                """
                
                df_schema = pd.read_sql_query(schema_query, conn, params=[self.schema_name, self.table_name])
                
                if df_schema.empty:
                    logger.error(f"‚ùå Table {self.schema_name}.{self.table_name} not found")
                    return None
                
                logger.info(f"‚úÖ Found table {self.schema_name}.{self.table_name} with {len(df_schema)} columns")
                
                # Get table size information
                count_query = f"SELECT COUNT(*) FROM {self.schema_name}.{self.table_name};"
                with conn.cursor() as cur:
                    cur.execute(count_query)
                    row_count = cur.fetchone()[0]
                
                # Get table size in bytes
                size_query = f"""
                SELECT pg_size_pretty(pg_total_relation_size('{self.schema_name}.{self.table_name}')) as size,
                       pg_total_relation_size('{self.schema_name}.{self.table_name}') as size_bytes;
                """
                with conn.cursor() as cur:
                    cur.execute(size_query)
                    size_result = cur.fetchone()
                    table_size = size_result[0] if size_result else "Unknown"
                    size_bytes = size_result[1] if size_result else 0
                
                return {
                    'schema': df_schema,
                    'row_count': row_count,
                    'table_size': table_size,
                    'size_bytes': size_bytes
                }
                
        except Exception as e:
            logger.error(f"‚ùå Schema analysis failed: {e}")
            return None
    
    def sample_data(self, limit=5):
        """Get sample data from the table"""
        try:
            with psycopg2.connect(**self.pg_config) as conn:
                sample_query = f"""
                SELECT * FROM {self.schema_name}.{self.table_name}
                ORDER BY 1
                LIMIT {limit};
                """
                
                df_sample = pd.read_sql_query(sample_query, conn)
                return df_sample
                
        except Exception as e:
            logger.error(f"‚ùå Sample data extraction failed: {e}")
            return None
    
    def analyze_data_patterns(self):
        """Analyze data patterns and quality"""
        try:
            with psycopg2.connect(**self.pg_config) as conn:
                # Get basic statistics
                stats_query = f"""
                SELECT 
                    COUNT(*) as total_rows,
                    COUNT(DISTINCT wallet_address) as unique_wallets,
                    MIN(timestamp) as earliest_record,
                    MAX(timestamp) as latest_record
                FROM {self.schema_name}.{self.table_name}
                WHERE timestamp IS NOT NULL;
                """
                
                with conn.cursor() as cur:
                    cur.execute(stats_query)
                    stats = cur.fetchone()
                    
                    if stats:
                        return {
                            'total_rows': stats[0],
                            'unique_wallets': stats[1],
                            'earliest_record': stats[2],
                            'latest_record': stats[3]
                        }
                    
        except Exception as e:
            logger.error(f"‚ùå Data pattern analysis failed: {e}")
            return None
    
    def run_analysis(self):
        """Run complete analysis and report results"""
        print("\n" + "="*60)
        print("WALLET TRADE HISTORY TABLE ANALYSIS")
        print("="*60)
        
        # Test connection
        if not self.test_connection():
            print("‚ùå Cannot connect to PostgreSQL database")
            return False
        
        # Analyze schema
        schema_info = self.analyze_table_schema()
        if not schema_info:
            print("‚ùå Cannot analyze table schema")
            return False
        
        # Print schema details
        print(f"\nüìä TABLE INFORMATION:")
        print(f"  Database: {self.pg_config['database']}")
        print(f"  Schema: {self.schema_name}")
        print(f"  Table: {self.table_name}")
        print(f"  Total Rows: {schema_info['row_count']:,}")
        print(f"  Table Size: {schema_info['table_size']}")
        print(f"  Columns: {len(schema_info['schema'])}")
        
        # Print column details
        print(f"\nüìã COLUMN SCHEMA:")
        for _, row in schema_info['schema'].iterrows():
            nullable = "NULL" if row['is_nullable'] == 'YES' else "NOT NULL"
            max_length = f"({row['character_maximum_length']})" if pd.notna(row['character_maximum_length']) else ""
            default = f" DEFAULT {row['column_default']}" if pd.notna(row['column_default']) else ""
            print(f"  {row['ordinal_position']:2d}. {row['column_name']:<25} | {row['data_type']}{max_length:<10} | {nullable}{default}")
        
        # Get sample data
        sample_data = self.sample_data()
        if sample_data is not None and not sample_data.empty:
            print(f"\nüìù SAMPLE DATA (first 5 rows):")
            # Print column headers
            headers = list(sample_data.columns)
            print("  " + " | ".join(f"{col:<15}" for col in headers[:5]))  # First 5 columns
            print("  " + "-" * (16 * min(5, len(headers)) - 2))
            
            # Print sample rows
            for idx, row in sample_data.head().iterrows():
                values = [str(row[col])[:15] for col in headers[:5]]  # First 5 columns, truncated
                print("  " + " | ".join(f"{val:<15}" for val in values))
        
        # Analyze data patterns
        patterns = self.analyze_data_patterns()
        if patterns:
            print(f"\nüìà DATA PATTERNS:")
            print(f"  Total Records: {patterns['total_rows']:,}")
            print(f"  Unique Wallets: {patterns['unique_wallets']:,}")
            print(f"  Date Range: {patterns['earliest_record']} to {patterns['latest_record']}")
            
            if patterns['earliest_record'] and patterns['latest_record']:
                date_range = patterns['latest_record'] - patterns['earliest_record']
                print(f"  Time Span: {date_range.days} days")
        
        print(f"\n‚úÖ Analysis complete. Ready for migration planning.")
        return True

if __name__ == "__main__":
    analyzer = WalletTradeHistoryAnalyzer()
    success = analyzer.run_analysis()
    exit(0 if success else 1)