#!/usr/bin/env python3
"""
PostgreSQL to MinIO Migration: Wallet Trade History

Migrates wallet_trade_history table from PostgreSQL (solana.public schema) 
to MinIO in unified format compatible with existing wallet transactions schema.

Features:
- Maps PostgreSQL fields to unified schema format
- Preserves all price and transaction data
- Handles nullable fields gracefully
- Provides comprehensive validation and progress tracking

Author: Generated by Claude Code
Date: 2025-06-19
"""

import os
import logging
import json
from typing import Dict, Optional
from datetime import datetime
import pandas as pd
import psycopg2
import boto3
from botocore.exceptions import ClientError
import pyarrow as pa
import pyarrow.parquet as pq

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class WalletTradeHistoryMigrator:
    """Migrates wallet_trade_history from PostgreSQL to MinIO"""
    
    def __init__(self):
        """Initialize connections and configuration"""
        
        # PostgreSQL connection (solana database)
        self.pg_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': int(os.getenv('DB_PORT', 5432)),
            'database': 'solana',  # Target database
            'user': os.getenv('DB_USER', 'postgres'),
            'password': os.getenv('DB_PASSWORD', 'St0ck!adePG')
        }
        
        # MinIO connection
        self.s3_client = boto3.client(
            's3',
            endpoint_url=os.getenv('MINIO_ENDPOINT', 'http://localhost:9000'),
            aws_access_key_id=os.getenv('MINIO_ACCESS_KEY', 'minioadmin'),
            aws_secret_access_key=os.getenv('MINIO_SECRET_KEY', 'minioadmin123'),
            region_name='us-east-1'
        )
        
        # Configuration
        self.source_table = 'public.wallet_trade_history'
        self.target_bucket = 'solana-data'
        self.target_path = 'bronze/wallet_trade_history_postgres/'
        self.batch_size = 1000  # Smaller batches for better handling
        
    def test_connections(self):
        """Test both PostgreSQL and MinIO connections"""
        logger.info("Testing connections...")
        
        # Test PostgreSQL
        try:
            with psycopg2.connect(**self.pg_config) as conn:
                with conn.cursor() as cur:
                    cur.execute("SELECT COUNT(*) FROM public.wallet_trade_history;")
                    count = cur.fetchone()[0]
                    logger.info(f"✅ PostgreSQL connected - {count:,} records in source table")
        except Exception as e:
            logger.error(f"❌ PostgreSQL connection failed: {e}")
            return False
        
        # Test MinIO
        try:
            self.s3_client.head_bucket(Bucket=self.target_bucket)
            logger.info(f"✅ MinIO connected - bucket '{self.target_bucket}' accessible")
        except ClientError:
            try:
                self.s3_client.create_bucket(Bucket=self.target_bucket)
                logger.info(f"✅ Created MinIO bucket '{self.target_bucket}'")
            except Exception as e:
                logger.error(f"❌ MinIO setup failed: {e}")
                return False
        
        return True
    
    def extract_and_transform_data(self) -> Optional[pd.DataFrame]:
        """Extract data from PostgreSQL and transform to unified schema"""
        try:
            with psycopg2.connect(**self.pg_config) as conn:
                
                # Extract with field mapping to unified schema
                query = """
                SELECT 
                    -- Core transaction identifiers
                    wallet_address,
                    tx_hash as transaction_hash,
                    fetched_at as timestamp,  -- Map fetched_at to timestamp
                    COALESCE(block_unix_time, 0) as block_slot,
                    
                    -- Unified token fields (PostgreSQL already uses base/quote format)
                    base_symbol as token_a,
                    quote_symbol as token_b,
                    COALESCE(base_ui_amount, 0) as amount_a,
                    COALESCE(quote_ui_amount, 0) as amount_b,
                    
                    -- USD value calculation
                    CASE 
                        WHEN base_price > 0 AND base_ui_amount > 0 THEN base_ui_amount * base_price
                        WHEN quote_price > 0 AND quote_ui_amount > 0 THEN quote_ui_amount * quote_price
                        ELSE 0
                    END as value_usd,
                    
                    -- Preserve price fields for PnL calculations
                    COALESCE(base_price, 0) as base_price,
                    COALESCE(quote_price, 0) as quote_price,
                    0 as nearest_price,  -- Not available in this source
                    
                    -- Transaction type from swap direction
                    CASE 
                        WHEN base_type_swap = 'out' AND quote_type_swap = 'in' THEN 'SELL'
                        WHEN base_type_swap = 'in' AND quote_type_swap = 'out' THEN 'BUY'
                        ELSE COALESCE(tx_type, 'SWAP')
                    END as transaction_type,
                    
                    -- Transaction metadata
                    0.0 as transaction_fee,  -- Not available
                    true as success,  -- Assume success if in table
                    '' as error_message,
                    
                    -- Processing metadata
                    fetched_at as processed_at,
                    'postgres_migration' as batch_id,
                    false as processed_for_pnl,
                    NULL as pnl_processed_at,
                    '' as pnl_processing_batch_id,
                    
                    -- Token details for PnL processing
                    base_address as token_a_address,
                    quote_address as token_b_address,
                    COALESCE(base_decimals, 9) as token_a_decimals,
                    COALESCE(quote_decimals, 6) as token_b_decimals,
                    
                    -- Source metadata
                    'postgres_wallet_trade_history' as schema_version,
                    'solana_postgres_db' as migration_source,
                    CURRENT_TIMESTAMP as migration_timestamp,
                    DATE(fetched_at) as partition_date,
                    
                    -- Additional fields from source
                    blockchain,
                    source,
                    owner,
                    base_type_swap,
                    quote_type_swap
                    
                FROM public.wallet_trade_history
                ORDER BY fetched_at, wallet_address;
                """
                
                logger.info("Extracting and transforming data from PostgreSQL...")
                df = pd.read_sql_query(query, conn)
                
                logger.info(f"✅ Extracted and transformed {len(df):,} records")
                return df
                
        except Exception as e:
            logger.error(f"❌ Data extraction failed: {e}")
            return None
    
    def upload_to_minio(self, df: pd.DataFrame) -> bool:
        """Upload transformed DataFrame to MinIO as partitioned Parquet"""
        try:
            logger.info("Uploading data to MinIO...")
            
            # Convert to PyArrow table for better Parquet handling
            table = pa.Table.from_pandas(df)
            
            # Write as single partitioned file
            import io
            buffer = io.BytesIO()
            pq.write_table(table, buffer, compression='snappy')
            buffer.seek(0)
            
            # Upload to MinIO with timestamp
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            key = f"{self.target_path}wallet_trade_history_{timestamp}.parquet"
            
            self.s3_client.put_object(
                Bucket=self.target_bucket,
                Key=key,
                Body=buffer.getvalue(),
                ContentType='application/octet-stream'
            )
            
            logger.info(f"✅ Uploaded {len(df):,} records to s3://{self.target_bucket}/{key}")
            return True
            
        except Exception as e:
            logger.error(f"❌ Upload to MinIO failed: {e}")
            return False
    
    def validate_migration(self) -> Dict:
        """Validate the migrated data"""
        try:
            # Get source count
            with psycopg2.connect(**self.pg_config) as conn:
                with conn.cursor() as cur:
                    cur.execute("SELECT COUNT(*) FROM public.wallet_trade_history;")
                    source_count = cur.fetchone()[0]
            
            # List objects in MinIO to verify upload
            try:
                response = self.s3_client.list_objects_v2(
                    Bucket=self.target_bucket,
                    Prefix=self.target_path
                )
                
                if 'Contents' in response:
                    files = [(obj['Key'], obj['Size']) for obj in response['Contents']]
                    total_size = sum(size for _, size in files)
                    
                    validation = {
                        'source_count': source_count,
                        'files_created': len(files),
                        'total_size_bytes': total_size,
                        'files': files,
                        'success': len(files) > 0
                    }
                else:
                    validation = {
                        'source_count': source_count,
                        'files_created': 0,
                        'success': False,
                        'error': 'No files found in MinIO'
                    }
                
                return validation
                
            except Exception as e:
                return {
                    'source_count': source_count,
                    'success': False,
                    'error': f"MinIO validation failed: {e}"
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f"Validation failed: {e}"
            }
    
    def run_migration(self):
        """Execute the complete migration process"""
        
        print("\n" + "="*60)
        print("WALLET TRADE HISTORY POSTGRES → MINIO MIGRATION")
        print("="*60)
        
        # Test connections
        if not self.test_connections():
            print("❌ Connection tests failed")
            return False
        
        # Extract and transform data
        df = self.extract_and_transform_data()
        if df is None or df.empty:
            print("❌ Data extraction failed or no data found")
            return False
        
        # Upload to MinIO
        if not self.upload_to_minio(df):
            print("❌ Upload to MinIO failed")
            return False
        
        # Validate migration
        validation = self.validate_migration()
        
        # Print results
        print(f"\n📊 MIGRATION RESULTS:")
        print(f"  Source Records: {validation.get('source_count', 'Unknown'):,}")
        print(f"  Files Created: {validation.get('files_created', 0)}")
        print(f"  Total Size: {validation.get('total_size_bytes', 0):,} bytes")
        
        if validation.get('files'):
            print(f"\n📂 FILES CREATED:")
            for file_path, size in validation['files']:
                print(f"  {file_path} ({size:,} bytes)")
        
        print(f"\n🔄 SCHEMA MAPPING:")
        print(f"  ✅ PostgreSQL base/quote format → Unified token_a/token_b")
        print(f"  ✅ Price fields preserved: base_price, quote_price")
        print(f"  ✅ Transaction types derived from swap directions")
        print(f"  ✅ USD values calculated from available price data")
        print(f"  ✅ All fields mapped to unified wallet transactions schema")
        
        print(f"\n📍 OUTPUT LOCATION:")
        print(f"  s3://{self.target_bucket}/{self.target_path}")
        
        if validation['success']:
            print(f"\n✅ MIGRATION COMPLETED SUCCESSFULLY!")
            print(f"📈 Ready to integrate with existing wallet transaction analysis")
            return True
        else:
            print(f"\n❌ MIGRATION FAILED: {validation.get('error', 'Unknown error')}")
            return False

if __name__ == "__main__":
    migrator = WalletTradeHistoryMigrator()
    success = migrator.run_migration()
    exit(0 if success else 1)