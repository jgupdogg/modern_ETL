{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solana Data Explorer - Simplified Analysis\n",
    "\n",
    "Simple analysis of wallet PnL and smart traders data.\n",
    "\n",
    "## Data Sources\n",
    "- **Silver Layer**: Wallet PnL metrics with FIFO methodology\n",
    "- **Gold Layer**: Filtered smart traders from silver data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"📊 Solana Data Explorer - Ready for Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔌 Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Connect to DuckDB with MinIO configuration\n# Note: Running from outside Docker, so we create a local connection\nconn = duckdb.connect()  # In-memory database since we're accessing S3 directly\n\n# Install and load httpfs extension for S3 access\ntry:\n    conn.execute(\"INSTALL httpfs;\")\nexcept:\n    pass  # Already installed\n    \nconn.execute(\"LOAD httpfs;\")\n\n# Configure S3/MinIO access - use localhost since we're outside Docker\nconn.execute(\"SET s3_endpoint='localhost:9000';\")\nconn.execute(\"SET s3_access_key_id='minioadmin';\")\nconn.execute(\"SET s3_secret_access_key='minioadmin123';\")\nconn.execute(\"SET s3_use_ssl=false;\")\nconn.execute(\"SET s3_url_style='path';\")\n\nprint(\"✅ Connected to DuckDB with MinIO S3 access (localhost)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Silver Wallet PnL - Complete Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ALL Silver Wallet PnL Data\n",
    "print(\"📊 Loading ALL Silver Wallet PnL Records...\")\n",
    "\n",
    "try:\n",
    "    silver_df = conn.execute(\"\"\"\n",
    "        SELECT * FROM read_parquet('s3://solana-data/silver/wallet_pnl/**/*.parquet')\n",
    "        ORDER BY wallet_address, time_period\n",
    "    \"\"\").df()\n",
    "    \n",
    "    print(f\"✅ Loaded {len(silver_df):,} silver wallet PnL records\")\n",
    "    print(f\"📊 Shape: {silver_df.shape}\")\n",
    "    print(f\"🏦 Unique Wallets: {silver_df['wallet_address'].nunique():,}\")\n",
    "    print(f\"⏰ Timeframes: {sorted(silver_df['time_period'].unique())}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading silver data: {e}\")\n",
    "    silver_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silver Data - Complete Column Statistics\n",
    "if not silver_df.empty:\n",
    "    print(\"🔍 SILVER WALLET PNL - COMPLETE COLUMN ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\n📊 Dataset Shape: {silver_df.shape}\")\n",
    "    print(f\"🏦 Unique Wallets: {silver_df['wallet_address'].nunique():,}\")\n",
    "    print(f\"⏰ Timeframes: {sorted(silver_df['time_period'].unique())}\")\n",
    "    \n",
    "    # Column data types\n",
    "    print(f\"\\n📋 Column Data Types:\")\n",
    "    for col, dtype in silver_df.dtypes.items():\n",
    "        null_count = silver_df[col].isnull().sum()\n",
    "        null_pct = (null_count / len(silver_df)) * 100\n",
    "        print(f\"  {col:25} | {str(dtype):15} | Nulls: {null_count:,} ({null_pct:.1f}%)\")\n",
    "    \n",
    "    # Numerical columns statistics\n",
    "    print(f\"\\n📈 NUMERICAL COLUMNS - DETAILED STATISTICS:\")\n",
    "    numerical_cols = silver_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        if col in silver_df.columns:\n",
    "            print(f\"\\n  📊 {col.upper()}:\")\n",
    "            stats = silver_df[col].describe()\n",
    "            print(f\"     Count: {stats['count']:,.0f}\")\n",
    "            print(f\"     Mean:  {stats['mean']:,.2f}\")\n",
    "            print(f\"     Std:   {stats['std']:,.2f}\")\n",
    "            print(f\"     Min:   {stats['min']:,.2f}\")\n",
    "            print(f\"     25%:   {stats['25%']:,.2f}\")\n",
    "            print(f\"     50%:   {stats['50%']:,.2f}\")\n",
    "            print(f\"     75%:   {stats['75%']:,.2f}\")\n",
    "            print(f\"     Max:   {stats['max']:,.2f}\")\n",
    "            \n",
    "            # Additional insights\n",
    "            positive_count = (silver_df[col] > 0).sum()\n",
    "            negative_count = (silver_df[col] < 0).sum()\n",
    "            zero_count = (silver_df[col] == 0).sum()\n",
    "            \n",
    "            print(f\"     Positive: {positive_count:,} ({positive_count/len(silver_df)*100:.1f}%)\")\n",
    "            print(f\"     Negative: {negative_count:,} ({negative_count/len(silver_df)*100:.1f}%)\")\n",
    "            print(f\"     Zero:     {zero_count:,} ({zero_count/len(silver_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Categorical columns\n",
    "    print(f\"\\n📝 CATEGORICAL COLUMNS:\")\n",
    "    categorical_cols = silver_df.select_dtypes(include=['object', 'string']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in silver_df.columns:\n",
    "            unique_count = silver_df[col].nunique()\n",
    "            print(f\"\\n  📊 {col.upper()}:\")\n",
    "            print(f\"     Unique values: {unique_count:,}\")\n",
    "            \n",
    "            if unique_count <= 20:  # Show value counts for small categories\n",
    "                value_counts = silver_df[col].value_counts()\n",
    "                for value, count in value_counts.items():\n",
    "                    print(f\"     {str(value):20} : {count:,} ({count/len(silver_df)*100:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"     Top 5 values:\")\n",
    "                top_values = silver_df[col].value_counts().head()\n",
    "                for value, count in top_values.items():\n",
    "                    print(f\"     {str(value)[:20]:20} : {count:,} ({count/len(silver_df)*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No silver data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🥇 Gold Smart Wallets - Complete Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Load ALL Gold Smart Wallets Data\nprint(\"🥇 Loading ALL Gold Smart Wallets Records...\")\n\n# Try multiple sources to find the gold data\n# Note: Since we're outside Docker, we can't access DuckDB tables directly\ngold_sources = [\n    \"read_parquet('s3://solana-data/gold/smart_wallets/**/*.parquet')\",  # Direct file\n    \"read_parquet('s3://webhook-data/gold/smart_wallets/**/*.parquet')\"   # Webhook bucket\n]\n\ngold_df = pd.DataFrame()\n\nfor source in gold_sources:\n    try:\n        gold_df = conn.execute(f\"SELECT * FROM {source} ORDER BY wallet_address\").df()\n        print(f\"✅ Loaded {len(gold_df):,} gold records from: {source}\")\n        print(f\"📊 Shape: {gold_df.shape}\")\n        print(f\"🏦 Unique Wallets: {gold_df['wallet_address'].nunique():,}\")\n        if 'time_period' in gold_df.columns:\n            print(f\"⏰ Timeframes: {sorted(gold_df['time_period'].unique())}\")\n        break\n    except Exception as e:\n        print(f\"❌ Failed to load from {source}: {e}\")\n        continue\n\nif gold_df.empty:\n    print(\"❌ No gold data found in any location\")\n    print(\"💡 Try running the DBT smart wallets DAG first to generate gold data\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold Data - Complete Column Statistics  \n",
    "if not gold_df.empty:\n",
    "    print(\"🔍 GOLD SMART WALLETS - COMPLETE COLUMN ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\n📊 Dataset Shape: {gold_df.shape}\")\n",
    "    print(f\"🏦 Unique Wallets: {gold_df['wallet_address'].nunique():,}\")\n",
    "    if 'time_period' in gold_df.columns:\n",
    "        print(f\"⏰ Timeframes: {sorted(gold_df['time_period'].unique())}\")\n",
    "    \n",
    "    # Column data types\n",
    "    print(f\"\\n📋 Column Data Types:\")\n",
    "    for col, dtype in gold_df.dtypes.items():\n",
    "        null_count = gold_df[col].isnull().sum()\n",
    "        null_pct = (null_count / len(gold_df)) * 100\n",
    "        print(f\"  {col:25} | {str(dtype):15} | Nulls: {null_count:,} ({null_pct:.1f}%)\")\n",
    "    \n",
    "    # Numerical columns statistics\n",
    "    print(f\"\\n📈 NUMERICAL COLUMNS - DETAILED STATISTICS:\")\n",
    "    numerical_cols = gold_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        if col in gold_df.columns:\n",
    "            print(f\"\\n  📊 {col.upper()}:\")\n",
    "            stats = gold_df[col].describe()\n",
    "            print(f\"     Count: {stats['count']:,.0f}\")\n",
    "            print(f\"     Mean:  {stats['mean']:,.3f}\")\n",
    "            print(f\"     Std:   {stats['std']:,.3f}\")\n",
    "            print(f\"     Min:   {stats['min']:,.3f}\")\n",
    "            print(f\"     25%:   {stats['25%']:,.3f}\")\n",
    "            print(f\"     50%:   {stats['50%']:,.3f}\")\n",
    "            print(f\"     75%:   {stats['75%']:,.3f}\")\n",
    "            print(f\"     Max:   {stats['max']:,.3f}\")\n",
    "            \n",
    "            # Additional insights for meaningful columns\n",
    "            if col in ['smart_trader_score', 'trade_frequency_daily', 'win_rate']:\n",
    "                positive_count = (gold_df[col] > 0).sum()\n",
    "                negative_count = (gold_df[col] < 0).sum()\n",
    "                zero_count = (gold_df[col] == 0).sum()\n",
    "                \n",
    "                print(f\"     Positive: {positive_count:,} ({positive_count/len(gold_df)*100:.1f}%)\")\n",
    "                print(f\"     Negative: {negative_count:,} ({negative_count/len(gold_df)*100:.1f}%)\")\n",
    "                print(f\"     Zero:     {zero_count:,} ({zero_count/len(gold_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Categorical columns\n",
    "    print(f\"\\n📝 CATEGORICAL COLUMNS:\")\n",
    "    categorical_cols = gold_df.select_dtypes(include=['object', 'string']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in gold_df.columns:\n",
    "            unique_count = gold_df[col].nunique()\n",
    "            print(f\"\\n  📊 {col.upper()}:\")\n",
    "            print(f\"     Unique values: {unique_count:,}\")\n",
    "            \n",
    "            # Always show value counts for categorical data\n",
    "            value_counts = gold_df[col].value_counts()\n",
    "            for value, count in value_counts.items():\n",
    "                pct = (count / len(gold_df)) * 100\n",
    "                print(f\"     {str(value):25} : {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Sample records\n",
    "    print(f\"\\n🎯 SAMPLE RECORDS (First 3):\")\n",
    "    print(gold_df.head(3).to_string())\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No gold data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Silver vs Gold Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Silver vs Gold layers\n",
    "if not silver_df.empty and not gold_df.empty:\n",
    "    print(\"🔄 SILVER vs GOLD LAYER COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Basic comparison\n",
    "    silver_wallets = silver_df['wallet_address'].nunique()\n",
    "    gold_wallets = gold_df['wallet_address'].nunique()\n",
    "    \n",
    "    print(f\"📊 RECORD COUNTS:\")\n",
    "    print(f\"  Silver Layer: {len(silver_df):,} records\")\n",
    "    print(f\"  Gold Layer:   {len(gold_df):,} records\")\n",
    "    \n",
    "    print(f\"\\n🏦 UNIQUE WALLETS:\")\n",
    "    print(f\"  Silver Layer: {silver_wallets:,} wallets\")\n",
    "    print(f\"  Gold Layer:   {gold_wallets:,} wallets\")\n",
    "    print(f\"  Filtered Out: {silver_wallets - gold_wallets:,} wallets\")\n",
    "    print(f\"  Filter Rate:  {((silver_wallets - gold_wallets)/silver_wallets*100):.1f}%\")\n",
    "    \n",
    "    # Timeframe comparison\n",
    "    if 'time_period' in silver_df.columns and 'time_period' in gold_df.columns:\n",
    "        silver_timeframes = set(silver_df['time_period'].unique())\n",
    "        gold_timeframes = set(gold_df['time_period'].unique())\n",
    "        \n",
    "        print(f\"\\n⏰ TIMEFRAME COVERAGE:\")\n",
    "        print(f\"  Silver Timeframes: {sorted(silver_timeframes)}\")\n",
    "        print(f\"  Gold Timeframes:   {sorted(gold_timeframes)}\")\n",
    "        \n",
    "        missing_in_gold = silver_timeframes - gold_timeframes\n",
    "        if missing_in_gold:\n",
    "            print(f\"  ⚠️  Missing in Gold: {sorted(missing_in_gold)}\")\n",
    "        \n",
    "        extra_in_gold = gold_timeframes - silver_timeframes\n",
    "        if extra_in_gold:\n",
    "            print(f\"  ℹ️  Extra in Gold: {sorted(extra_in_gold)}\")\n",
    "    \n",
    "    # Column comparison\n",
    "    silver_cols = set(silver_df.columns)\n",
    "    gold_cols = set(gold_df.columns)\n",
    "    \n",
    "    print(f\"\\n📋 COLUMN COMPARISON:\")\n",
    "    print(f\"  Silver Columns: {len(silver_cols)}\")\n",
    "    print(f\"  Gold Columns:   {len(gold_cols)}\")\n",
    "    \n",
    "    common_cols = silver_cols & gold_cols\n",
    "    silver_only = silver_cols - gold_cols  \n",
    "    gold_only = gold_cols - silver_cols\n",
    "    \n",
    "    print(f\"  Common:         {len(common_cols)}\")\n",
    "    print(f\"  Silver Only:    {len(silver_only)}\")\n",
    "    print(f\"  Gold Only:      {len(gold_only)}\")\n",
    "    \n",
    "    if silver_only:\n",
    "        print(f\"\\n  📊 Silver-only columns: {sorted(silver_only)}\")\n",
    "    \n",
    "    if gold_only:\n",
    "        print(f\"\\n  🥇 Gold-only columns: {sorted(gold_only)}\")\n",
    "\n",
    "elif not silver_df.empty:\n",
    "    print(\"⚠️ Only Silver data available - cannot compare with Gold\")\n",
    "elif not gold_df.empty:\n",
    "    print(\"⚠️ Only Gold data available - cannot compare with Silver\")\n",
    "else:\n",
    "    print(\"❌ No data available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary Report\n",
    "print(\"📋 SOLANA DATA PIPELINE - SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"🕐 Report Generated: {current_time}\")\n",
    "\n",
    "# Silver layer summary\n",
    "if not silver_df.empty:\n",
    "    print(f\"\\n✅ SILVER WALLET PNL LAYER:\")\n",
    "    print(f\"   📊 Records: {len(silver_df):,}\")\n",
    "    print(f\"   🏦 Unique Wallets: {silver_df['wallet_address'].nunique():,}\")\n",
    "    print(f\"   ⏰ Timeframes: {len(silver_df['time_period'].unique())}\")\n",
    "    \n",
    "    # PnL insights\n",
    "    if 'total_pnl' in silver_df.columns:\n",
    "        profitable = (silver_df['total_pnl'] > 0).sum()\n",
    "        avg_pnl = silver_df['total_pnl'].mean()\n",
    "        print(f\"   💰 Profitable Records: {profitable:,}/{len(silver_df):,} ({profitable/len(silver_df)*100:.1f}%)\")\n",
    "        print(f\"   📈 Average PnL: ${avg_pnl:.2f}\")\n",
    "    \n",
    "    # Trading activity\n",
    "    if 'trade_count' in silver_df.columns:\n",
    "        total_trades = silver_df['trade_count'].sum()\n",
    "        avg_trades = silver_df['trade_count'].mean()\n",
    "        print(f\"   🔄 Total Trades: {total_trades:,.0f}\")\n",
    "        print(f\"   📊 Avg Trades/Wallet: {avg_trades:.1f}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n❌ SILVER LAYER: No data available\")\n",
    "\n",
    "# Gold layer summary  \n",
    "if not gold_df.empty:\n",
    "    print(f\"\\n✅ GOLD SMART WALLETS LAYER:\")\n",
    "    print(f\"   📊 Records: {len(gold_df):,}\")\n",
    "    print(f\"   🏦 Unique Wallets: {gold_df['wallet_address'].nunique():,}\")\n",
    "    \n",
    "    if 'time_period' in gold_df.columns:\n",
    "        print(f\"   ⏰ Timeframes: {len(gold_df['time_period'].unique())}\")\n",
    "    \n",
    "    # Classifications\n",
    "    if 'trader_classification' in gold_df.columns:\n",
    "        classifications = gold_df['trader_classification'].value_counts()\n",
    "        print(f\"   🏆 Classifications:\")\n",
    "        for classification, count in classifications.items():\n",
    "            print(f\"      {classification}: {count:,}\")\n",
    "    \n",
    "    # Smart trader scores\n",
    "    if 'smart_trader_score' in gold_df.columns:\n",
    "        avg_score = gold_df['smart_trader_score'].mean()\n",
    "        max_score = gold_df['smart_trader_score'].max()\n",
    "        print(f\"   🎯 Avg Smart Score: {avg_score:.3f}\")\n",
    "        print(f\"   🏆 Max Smart Score: {max_score:.3f}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n❌ GOLD LAYER: No data available\")\n",
    "\n",
    "# Pipeline effectiveness\n",
    "if not silver_df.empty and not gold_df.empty:\n",
    "    silver_wallets = silver_df['wallet_address'].nunique()\n",
    "    gold_wallets = gold_df['wallet_address'].nunique()\n",
    "    filter_rate = ((silver_wallets - gold_wallets) / silver_wallets) * 100\n",
    "    \n",
    "    print(f\"\\n🔧 PIPELINE EFFECTIVENESS:\")\n",
    "    print(f\"   📥 Input: {silver_wallets:,} wallets\")\n",
    "    print(f\"   📤 Output: {gold_wallets:,} wallets\")\n",
    "    print(f\"   🚫 Filtered: {filter_rate:.1f}%\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\n💡 RECOMMENDATIONS:\")\n",
    "\n",
    "if not silver_df.empty and 'total_pnl' in silver_df.columns:\n",
    "    profitable_pct = (silver_df['total_pnl'] > 0).sum() / len(silver_df) * 100\n",
    "    if profitable_pct == 0:\n",
    "        print(f\"   ⚠️  No profitable wallets found - review PnL calculation\")\n",
    "    elif profitable_pct < 10:\n",
    "        print(f\"   ⚠️  Very low profitability ({profitable_pct:.1f}%) - check data quality\")\n",
    "\n",
    "if not silver_df.empty and not gold_df.empty:\n",
    "    filter_rate = ((silver_df['wallet_address'].nunique() - gold_df['wallet_address'].nunique()) / \n",
    "                   silver_df['wallet_address'].nunique()) * 100\n",
    "    if filter_rate < 5:\n",
    "        print(f\"   ⚠️  Low filtering rate ({filter_rate:.1f}%) - consider tightening criteria\")\n",
    "    \n",
    "    if 'time_period' in gold_df.columns and 'time_period' in silver_df.columns:\n",
    "        if len(gold_df['time_period'].unique()) < len(silver_df['time_period'].unique()):\n",
    "            print(f\"   ⚠️  Missing timeframes in gold layer - run DBT for all periods\")\n",
    "\n",
    "print(f\"\\n🔚 Analysis Complete - Data pipeline review finished\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test Updated Gold Criteria (DBT Logic)\nprint(\"🧪 TESTING UPDATED GOLD CRITERIA - DBT LOGIC\")\nprint(\"=\"*70)\n\n# Reconnect to test the updated criteria\nconn = duckdb.connect()\nconn.execute(\"INSTALL httpfs;\")\nconn.execute(\"LOAD httpfs;\")\nconn.execute(\"SET s3_endpoint='localhost:9000';\")\nconn.execute(\"SET s3_access_key_id='minioadmin';\")\nconn.execute(\"SET s3_secret_access_key='minioadmin123';\")\nconn.execute(\"SET s3_use_ssl=false;\")\nconn.execute(\"SET s3_url_style='path';\")\n\n# Test the exact DBT logic\nprint(\"🔍 Testing filter criteria from updated dbt model...\")\n\ntry:\n    # Apply the exact filtering logic from our updated dbt model\n    dbt_gold_test = conn.execute(\"\"\"\n    WITH silver_wallet_pnl AS (\n        SELECT *\n        FROM read_parquet('s3://solana-data/silver/wallet_pnl/**/*.parquet')\n    ),\n    \n    filtered_smart_wallets AS (\n        SELECT \n            wallet_address,\n            time_period,\n            trade_count,\n            win_rate,\n            total_pnl,\n            roi,\n            realized_pnl,\n            unrealized_pnl,\n            total_bought,\n            total_sold,\n            processed_for_gold\n        FROM silver_wallet_pnl\n        WHERE \n            -- Focus on portfolio-level records for 'all' timeframe\n            token_address = 'ALL_TOKENS' \n            AND time_period = 'all'\n            \n            -- Updated gold criteria matching smart_trader_config.py\n            AND total_pnl >= 10.0           -- MIN_TOTAL_PNL = 10.0\n            AND roi >= 1.0                  -- MIN_ROI_PERCENT = 1.0\n            AND win_rate >= 40.0            -- MIN_WIN_RATE_PERCENT = 40.0\n            AND trade_count >= 1            -- MIN_TRADE_COUNT = 1\n            AND total_pnl > 0               -- Must be profitable\n            \n            -- Only process unprocessed records\n            AND processed_for_gold = false\n    ),\n    \n    tier_classification AS (\n        SELECT \n            *,\n            -- Performance tier classification matching smart_trader_config.py\n            CASE \n                WHEN total_pnl >= 1000 AND roi >= 30 AND win_rate >= 60 AND trade_count >= 10 THEN 'elite'\n                WHEN total_pnl >= 100 AND roi >= 15 AND win_rate >= 40 AND trade_count >= 5 THEN 'strong'\n                ELSE 'promising'\n            END as performance_tier\n        FROM filtered_smart_wallets\n    )\n    \n    SELECT \n        COUNT(*) as total_qualifying,\n        COUNT(CASE WHEN performance_tier = 'elite' THEN 1 END) as elite_count,\n        COUNT(CASE WHEN performance_tier = 'strong' THEN 1 END) as strong_count,\n        COUNT(CASE WHEN performance_tier = 'promising' THEN 1 END) as promising_count,\n        AVG(total_pnl) as avg_pnl,\n        AVG(roi) as avg_roi,\n        AVG(win_rate) as avg_win_rate,\n        AVG(trade_count) as avg_trades\n    FROM tier_classification\n    \"\"\").fetchone()\n    \n    if dbt_gold_test:\n        total, elite, strong, promising, avg_pnl, avg_roi, avg_win_rate, avg_trades = dbt_gold_test\n        \n        print(f\"\\n✅ DBT FILTER TEST RESULTS:\")\n        print(f\"   📊 Total Qualifying: {total}\")\n        print(f\"   🏆 Elite Tier: {elite}\")\n        print(f\"   💪 Strong Tier: {strong}\")  \n        print(f\"   🌟 Promising Tier: {promising}\")\n        print(f\"   💰 Average PnL: ${avg_pnl:.2f}\")\n        print(f\"   📈 Average ROI: {avg_roi:.2f}%\")\n        print(f\"   🎯 Average Win Rate: {avg_win_rate:.1f}%\")\n        print(f\"   🔄 Average Trades: {avg_trades:.1f}\")\n        \n        if total > 0:\n            print(f\"\\n🎉 SUCCESS: Found {total} qualifying candidates!\")\n            \n            # Get sample records\n            sample_records = conn.execute(\"\"\"\n            WITH silver_wallet_pnl AS (\n                SELECT *\n                FROM read_parquet('s3://solana-data/silver/wallet_pnl/**/*.parquet')\n            ),\n            \n            filtered_smart_wallets AS (\n                SELECT \n                    wallet_address,\n                    time_period,\n                    trade_count,\n                    win_rate,\n                    total_pnl,\n                    roi,\n                    realized_pnl,\n                    unrealized_pnl,\n                    total_bought,\n                    total_sold,\n                    processed_for_gold\n                FROM silver_wallet_pnl\n                WHERE \n                    token_address = 'ALL_TOKENS' \n                    AND time_period = 'all'\n                    AND total_pnl >= 10.0\n                    AND roi >= 1.0\n                    AND win_rate >= 40.0\n                    AND trade_count >= 1\n                    AND total_pnl > 0\n                    AND processed_for_gold = false\n            )\n            \n            SELECT \n                wallet_address,\n                total_pnl,\n                roi,\n                win_rate,\n                trade_count,\n                CASE \n                    WHEN total_pnl >= 1000 AND roi >= 30 AND win_rate >= 60 AND trade_count >= 10 THEN 'elite'\n                    WHEN total_pnl >= 100 AND roi >= 15 AND win_rate >= 40 AND trade_count >= 5 THEN 'strong'\n                    ELSE 'promising'\n                END as performance_tier\n            FROM filtered_smart_wallets\n            ORDER BY total_pnl DESC\n            LIMIT 5\n            \"\"\").fetchall()\n            \n            print(f\"\\n🔝 TOP 5 QUALIFYING CANDIDATES:\")\n            for i, (wallet, pnl, roi, win_rate, trades, tier) in enumerate(sample_records):\n                print(f\"   {i+1}. {wallet[:10]}... | PnL: ${pnl:.2f} | ROI: {roi:.2f}% | Win: {win_rate:.1f}% | Trades: {trades} | Tier: {tier.upper()}\")\n        \n        else:\n            print(f\"\\n❌ NO QUALIFYING CANDIDATES\")\n            print(f\"   The updated criteria are too strict or there's no unprocessed data\")\n            \n            # Debug: check without processed_for_gold filter\n            debug_test = conn.execute(\"\"\"\n            SELECT COUNT(*) as total_without_filter\n            FROM read_parquet('s3://solana-data/silver/wallet_pnl/**/*.parquet')\n            WHERE \n                token_address = 'ALL_TOKENS' \n                AND time_period = 'all'\n                AND total_pnl >= 10.0\n                AND roi >= 1.0\n                AND win_rate >= 40.0\n                AND trade_count >= 1\n                AND total_pnl > 0\n            \"\"\").fetchone()\n            \n            if debug_test:\n                total_without_filter = debug_test[0]\n                print(f\"   💡 Debug: {total_without_filter} candidates WITHOUT processed_for_gold filter\")\n                if total_without_filter > 0:\n                    print(f\"   ➡️  Recommendation: Reset processed_for_gold flags or ignore this filter\")\n    \nexcept Exception as e:\n    print(f\"❌ Error testing DBT logic: {e}\")\n\nprint(f\"\\n✅ DBT Logic Test Complete\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}