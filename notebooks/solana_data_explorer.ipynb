{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solana Data Explorer - Simplified Analysis\n",
    "\n",
    "Simple analysis of wallet PnL and smart traders data.\n",
    "\n",
    "## Data Sources\n",
    "- **Silver Layer**: Wallet PnL metrics with FIFO methodology\n",
    "- **Gold Layer**: Filtered smart traders from silver data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"📊 Solana Data Explorer - Ready for Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔌 Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Connect to DuckDB with MinIO configuration\n# Note: Running from outside Docker, so we create a local connection\nconn = duckdb.connect()  # In-memory database since we're accessing S3 directly\n\n# Install and load httpfs extension for S3 access\ntry:\n    conn.execute(\"INSTALL httpfs;\")\nexcept:\n    pass  # Already installed\n    \nconn.execute(\"LOAD httpfs;\")\n\n# Configure S3/MinIO access - use localhost since we're outside Docker\nconn.execute(\"SET s3_endpoint='localhost:9000';\")\nconn.execute(\"SET s3_access_key_id='minioadmin';\")\nconn.execute(\"SET s3_secret_access_key='minioadmin123';\")\nconn.execute(\"SET s3_use_ssl=false;\")\nconn.execute(\"SET s3_url_style='path';\")\n\nprint(\"✅ Connected to DuckDB with MinIO S3 access (localhost)\")\nprint(\"🔌 Ready to query Solana data from bronze, silver, and gold layers\")"
  },
  {
   "cell_type": "code",
   "source": "# Load Bronze Transaction Data\nprint(\"📦 Loading Bronze Transaction Data...\")\n\n# Try both legacy and raw bronze transaction paths\nbronze_sources = [\n    (\"Raw Transactions\", \"s3://solana-data/bronze/wallet_transactions_raw/**/*.parquet\"),\n    (\"Legacy Transactions\", \"s3://solana-data/bronze/wallet_transactions/**/*.parquet\")\n]\n\nbronze_df = pd.DataFrame()\nbronze_source_used = None\n\nfor source_name, source_path in bronze_sources:\n    try:\n        bronze_df = conn.execute(f\"\"\"\n            SELECT * FROM read_parquet('{source_path}')\n            ORDER BY timestamp DESC\n            LIMIT 10000\n        \"\"\").df()\n        \n        if not bronze_df.empty:\n            bronze_source_used = source_name\n            print(f\"✅ Loaded {len(bronze_df):,} bronze records from: {source_name}\")\n            print(f\"📊 Shape: {bronze_df.shape}\")\n            print(f\"🏦 Unique Wallets: {bronze_df['wallet_address'].nunique():,}\")\n            print(f\"📅 Date Range: {bronze_df['timestamp'].min()} to {bronze_df['timestamp'].max()}\")\n            break\n    except Exception as e:\n        print(f\"❌ Failed to load {source_name}: {e}\")\n        continue\n\nif bronze_df.empty:\n    print(\"❌ No bronze transaction data found\")\n    print(\"💡 Check if bronze wallet transactions have been fetched\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 📦 Bronze Transaction Data - Raw Analysis",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Bronze Data Analysis\nif not bronze_df.empty:\n    print(\"🔍 BRONZE TRANSACTION DATA - DETAILED ANALYSIS\")\n    print(\"=\"*70)\n    \n    # Basic statistics\n    print(f\"\\n📊 DATASET OVERVIEW:\")\n    print(f\"   Records: {len(bronze_df):,}\")\n    print(f\"   Wallets: {bronze_df['wallet_address'].nunique():,}\")\n    print(f\"   Source: {bronze_source_used}\")\n    \n    # Column analysis\n    print(f\"\\n📋 COLUMN STRUCTURE:\")\n    for col, dtype in bronze_df.dtypes.items():\n        null_count = bronze_df[col].isnull().sum()\n        null_pct = (null_count / len(bronze_df)) * 100\n        print(f\"   {col:30} | {str(dtype):15} | Nulls: {null_count:,} ({null_pct:.1f}%)\")\n    \n    # Transaction analysis based on data type\n    if bronze_source_used == \"Raw Transactions\":\n        print(f\"\\n🔄 RAW TRANSACTION ANALYSIS:\")\n        \n        # Swap direction analysis\n        if 'base_type_swap' in bronze_df.columns and 'quote_type_swap' in bronze_df.columns:\n            print(f\"\\n   📊 Swap Direction Patterns:\")\n            swap_patterns = bronze_df.groupby(['base_type_swap', 'quote_type_swap']).size().reset_index(name='count')\n            for _, row in swap_patterns.iterrows():\n                pct = (row['count'] / len(bronze_df)) * 100\n                print(f\"      {row['base_type_swap']} → {row['quote_type_swap']}: {row['count']:,} ({pct:.1f}%)\")\n        \n        # Token analysis\n        if 'base_symbol' in bronze_df.columns and 'quote_symbol' in bronze_df.columns:\n            print(f\"\\n   🪙 TOKEN ANALYSIS:\")\n            all_tokens = pd.concat([\n                bronze_df['base_symbol'].dropna(),\n                bronze_df['quote_symbol'].dropna()\n            ]).value_counts().head(10)\n            \n            print(f\"      Top 10 Tokens in Swaps:\")\n            for token, count in all_tokens.items():\n                print(f\"         {token}: {count:,} occurrences\")\n        \n        # Processing status\n        if 'processed_for_pnl' in bronze_df.columns:\n            processed_count = bronze_df['processed_for_pnl'].sum()\n            unprocessed_count = len(bronze_df) - processed_count\n            print(f\"\\n   🔄 PnL PROCESSING STATUS:\")\n            print(f\"      Processed: {processed_count:,} ({processed_count/len(bronze_df)*100:.1f}%)\")\n            print(f\"      Unprocessed: {unprocessed_count:,} ({unprocessed_count/len(bronze_df)*100:.1f}%)\")\n    \n    else:  # Legacy transactions\n        print(f\"\\n🔄 LEGACY TRANSACTION ANALYSIS:\")\n        \n        # Transaction type analysis\n        if 'transaction_type' in bronze_df.columns:\n            txn_types = bronze_df['transaction_type'].value_counts()\n            print(f\"\\n   📊 Transaction Types:\")\n            for txn_type, count in txn_types.items():\n                pct = (count / len(bronze_df)) * 100\n                print(f\"      {txn_type}: {count:,} ({pct:.1f}%)\")\n        \n        # Token analysis\n        if 'from_symbol' in bronze_df.columns and 'to_symbol' in bronze_df.columns:\n            print(f\"\\n   🪙 TOKEN ANALYSIS:\")\n            all_tokens = pd.concat([\n                bronze_df['from_symbol'].dropna(),\n                bronze_df['to_symbol'].dropna()\n            ]).value_counts().head(10)\n            \n            print(f\"      Top 10 Tokens:\")\n            for token, count in all_tokens.items():\n                print(f\"         {token}: {count:,} occurrences\")\n    \n    # Sample records\n    print(f\"\\n📋 SAMPLE RECORDS (First 3):\")\n    sample_cols = ['wallet_address', 'timestamp', 'transaction_hash']\n    if bronze_source_used == \"Raw Transactions\":\n        sample_cols.extend(['base_symbol', 'base_type_swap', 'quote_symbol', 'quote_type_swap'])\n    else:\n        sample_cols.extend(['transaction_type', 'from_symbol', 'to_symbol'])\n    \n    # Only include columns that exist\n    available_cols = [col for col in sample_cols if col in bronze_df.columns]\n    sample_df = bronze_df[available_cols].head(3)\n    \n    for idx, row in sample_df.iterrows():\n        print(f\"\\n   Record {idx + 1}:\")\n        for col in available_cols:\n            value = str(row[col])\n            if len(value) > 50:\n                value = value[:50] + \"...\"\n            print(f\"      {col}: {value}\")\n\nelse:\n    print(\"❌ No bronze transaction data available for analysis\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Silver Wallet PnL - Complete Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "## 💰 Silver Wallet PnL - Portfolio Analysis"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Load Silver Wallet PnL Data\nprint(\"💰 Loading Silver Wallet PnL Data...\")\n\n# Try multiple silver PnL sources\nsilver_sources = [\n    (\"Comprehensive PnL\", \"s3://solana-data/silver/wallet_pnl_comprehensive/**/*.parquet\"),\n    (\"Standard PnL\", \"s3://solana-data/silver/wallet_pnl/**/*.parquet\")\n]\n\nsilver_df = pd.DataFrame()\nsilver_source_used = None\n\nfor source_name, source_path in silver_sources:\n    try:\n        silver_df = conn.execute(f\"\"\"\n            SELECT * FROM read_parquet('{source_path}')\n            ORDER BY wallet_address, time_period, token_address\n        \"\"\").df()\n        \n        if not silver_df.empty:\n            silver_source_used = source_name\n            print(f\"✅ Loaded {len(silver_df):,} silver PnL records from: {source_name}\")\n            print(f\"📊 Shape: {silver_df.shape}\")\n            print(f\"🏦 Unique Wallets: {silver_df['wallet_address'].nunique():,}\")\n            \n            if 'time_period' in silver_df.columns:\n                print(f\"⏰ Timeframes: {sorted(silver_df['time_period'].unique())}\")\n            \n            if 'token_address' in silver_df.columns:\n                unique_tokens = silver_df['token_address'].nunique()\n                portfolio_records = (silver_df['token_address'] == 'ALL_TOKENS').sum()\n                print(f\"🪙 Unique Tokens: {unique_tokens:,}\")\n                print(f\"📋 Portfolio Records: {portfolio_records:,}\")\n            \n            break\n    except Exception as e:\n        print(f\"❌ Failed to load {source_name}: {e}\")\n        continue\n\nif silver_df.empty:\n    print(\"❌ No silver PnL data found\")\n    print(\"💡 Check if silver wallet PnL processing has been completed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Silver Wallet PnL Analysis\nif not silver_df.empty:\n    print(\"🔍 SILVER WALLET PNL - COMPREHENSIVE ANALYSIS\")\n    print(\"=\"*70)\n    \n    # Dataset overview\n    print(f\"\\n📊 DATASET OVERVIEW:\")\n    print(f\"   Records: {len(silver_df):,}\")\n    print(f\"   Wallets: {silver_df['wallet_address'].nunique():,}\")\n    print(f\"   Source: {silver_source_used}\")\n    \n    # Portfolio vs Token-level breakdown\n    if 'token_address' in silver_df.columns:\n        portfolio_records = silver_df[silver_df['token_address'] == 'ALL_TOKENS']\n        token_records = silver_df[silver_df['token_address'] != 'ALL_TOKENS']\n        \n        print(f\"\\n📋 RECORD TYPES:\")\n        print(f\"   Portfolio-level (ALL_TOKENS): {len(portfolio_records):,}\")\n        print(f\"   Token-specific: {len(token_records):,}\")\n        \n        # Analyze portfolio-level records (most important for smart trader identification)\n        if not portfolio_records.empty:\n            print(f\"\\n💼 PORTFOLIO-LEVEL ANALYSIS:\")\n            \n            # PnL distribution\n            if 'total_pnl' in portfolio_records.columns:\n                profitable = (portfolio_records['total_pnl'] > 0).sum()\n                avg_pnl = portfolio_records['total_pnl'].mean()\n                median_pnl = portfolio_records['total_pnl'].median()\n                max_pnl = portfolio_records['total_pnl'].max()\n                min_pnl = portfolio_records['total_pnl'].min()\n                \n                print(f\"   💰 PnL METRICS:\")\n                print(f\"      Profitable: {profitable:,}/{len(portfolio_records):,} ({profitable/len(portfolio_records)*100:.1f}%)\")\n                print(f\"      Average PnL: ${avg_pnl:.2f}\")\n                print(f\"      Median PnL: ${median_pnl:.2f}\")\n                print(f\"      Max PnL: ${max_pnl:.2f}\")\n                print(f\"      Min PnL: ${min_pnl:.2f}\")\n            \n            # Trading activity\n            if 'trade_count' in portfolio_records.columns:\n                total_trades = portfolio_records['trade_count'].sum()\n                avg_trades = portfolio_records['trade_count'].mean()\n                max_trades = portfolio_records['trade_count'].max()\n                \n                print(f\"   🔄 TRADING ACTIVITY:\")\n                print(f\"      Total Trades: {total_trades:,.0f}\")\n                print(f\"      Avg Trades/Wallet: {avg_trades:.1f}\")\n                print(f\"      Max Trades: {max_trades:,.0f}\")\n            \n            # Win rates\n            if 'win_rate' in portfolio_records.columns:\n                avg_win_rate = portfolio_records['win_rate'].mean()\n                high_win_rate = (portfolio_records['win_rate'] >= 50).sum()\n                \n                print(f\"   🎯 WIN RATES:\")\n                print(f\"      Average Win Rate: {avg_win_rate:.1f}%\")\n                print(f\"      High Win Rate (≥50%): {high_win_rate:,} wallets\")\n            \n            # ROI analysis\n            if 'roi' in portfolio_records.columns:\n                avg_roi = portfolio_records['roi'].mean()\n                positive_roi = (portfolio_records['roi'] > 0).sum()\n                \n                print(f\"   📈 ROI ANALYSIS:\")\n                print(f\"      Average ROI: {avg_roi:.2f}%\")\n                print(f\"      Positive ROI: {positive_roi:,}/{len(portfolio_records):,} ({positive_roi/len(portfolio_records)*100:.1f}%)\")\n        \n        # Top performers\n        if not portfolio_records.empty and 'total_pnl' in portfolio_records.columns:\n            print(f\"\\n🏆 TOP 5 PERFORMERS (by Total PnL):\")\n            top_performers = portfolio_records.nlargest(5, 'total_pnl')\n            \n            for idx, (_, wallet) in enumerate(top_performers.iterrows()):\n                print(f\"   {idx+1}. {wallet['wallet_address'][:10]}...\")\n                print(f\"      PnL: ${wallet['total_pnl']:.2f}\")\n                if 'roi' in wallet:\n                    print(f\"      ROI: {wallet['roi']:.2f}%\")\n                if 'win_rate' in wallet:\n                    print(f\"      Win Rate: {wallet['win_rate']:.1f}%\")\n                if 'trade_count' in wallet:\n                    print(f\"      Trades: {wallet['trade_count']:.0f}\")\n    \n    # Processing status\n    if 'processed_for_gold' in silver_df.columns:\n        processed_for_gold = silver_df['processed_for_gold'].sum()\n        total_records = len(silver_df)\n        \n        print(f\"\\n🔄 GOLD PROCESSING STATUS:\")\n        print(f\"   Processed for Gold: {processed_for_gold:,}/{total_records:,} ({processed_for_gold/total_records*100:.1f}%)\")\n        print(f\"   Pending for Gold: {total_records - processed_for_gold:,}\")\n\nelse:\n    print(\"❌ No silver PnL data available for analysis\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Load ALL Gold Smart Wallets Data\nprint(\"🥇 Loading ALL Gold Smart Wallets Records...\")\n\n# Try multiple sources to find the gold data\n# Note: Since we're outside Docker, we can't access DuckDB tables directly\ngold_sources = [\n    \"read_parquet('s3://solana-data/gold/smart_wallets/**/*.parquet')\",  # Direct file\n    \"read_parquet('s3://webhook-data/gold/smart_wallets/**/*.parquet')\"   # Webhook bucket\n]\n\ngold_df = pd.DataFrame()\n\nfor source in gold_sources:\n    try:\n        gold_df = conn.execute(f\"SELECT * FROM {source} ORDER BY wallet_address\").df()\n        print(f\"✅ Loaded {len(gold_df):,} gold records from: {source}\")\n        print(f\"📊 Shape: {gold_df.shape}\")\n        print(f\"🏦 Unique Wallets: {gold_df['wallet_address'].nunique():,}\")\n        if 'time_period' in gold_df.columns:\n            print(f\"⏰ Timeframes: {sorted(gold_df['time_period'].unique())}\")\n        break\n    except Exception as e:\n        print(f\"❌ Failed to load from {source}: {e}\")\n        continue\n\nif gold_df.empty:\n    print(\"❌ No gold data found in any location\")\n    print(\"💡 Try running the DBT smart wallets DAG first to generate gold data\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gold Data - Complete Column Statistics  \n",
    "if not gold_df.empty:\n",
    "    print(\"🔍 GOLD SMART WALLETS - COMPLETE COLUMN ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\n📊 Dataset Shape: {gold_df.shape}\")\n",
    "    print(f\"🏦 Unique Wallets: {gold_df['wallet_address'].nunique():,}\")\n",
    "    if 'time_period' in gold_df.columns:\n",
    "        print(f\"⏰ Timeframes: {sorted(gold_df['time_period'].unique())}\")\n",
    "    \n",
    "    # Column data types\n",
    "    print(f\"\\n📋 Column Data Types:\")\n",
    "    for col, dtype in gold_df.dtypes.items():\n",
    "        null_count = gold_df[col].isnull().sum()\n",
    "        null_pct = (null_count / len(gold_df)) * 100\n",
    "        print(f\"  {col:25} | {str(dtype):15} | Nulls: {null_count:,} ({null_pct:.1f}%)\")\n",
    "    \n",
    "    # Numerical columns statistics\n",
    "    print(f\"\\n📈 NUMERICAL COLUMNS - DETAILED STATISTICS:\")\n",
    "    numerical_cols = gold_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        if col in gold_df.columns:\n",
    "            print(f\"\\n  📊 {col.upper()}:\")\n",
    "            stats = gold_df[col].describe()\n",
    "            print(f\"     Count: {stats['count']:,.0f}\")\n",
    "            print(f\"     Mean:  {stats['mean']:,.3f}\")\n",
    "            print(f\"     Std:   {stats['std']:,.3f}\")\n",
    "            print(f\"     Min:   {stats['min']:,.3f}\")\n",
    "            print(f\"     25%:   {stats['25%']:,.3f}\")\n",
    "            print(f\"     50%:   {stats['50%']:,.3f}\")\n",
    "            print(f\"     75%:   {stats['75%']:,.3f}\")\n",
    "            print(f\"     Max:   {stats['max']:,.3f}\")\n",
    "            \n",
    "            # Additional insights for meaningful columns\n",
    "            if col in ['smart_trader_score', 'trade_frequency_daily', 'win_rate']:\n",
    "                positive_count = (gold_df[col] > 0).sum()\n",
    "                negative_count = (gold_df[col] < 0).sum()\n",
    "                zero_count = (gold_df[col] == 0).sum()\n",
    "                \n",
    "                print(f\"     Positive: {positive_count:,} ({positive_count/len(gold_df)*100:.1f}%)\")\n",
    "                print(f\"     Negative: {negative_count:,} ({negative_count/len(gold_df)*100:.1f}%)\")\n",
    "                print(f\"     Zero:     {zero_count:,} ({zero_count/len(gold_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Categorical columns\n",
    "    print(f\"\\n📝 CATEGORICAL COLUMNS:\")\n",
    "    categorical_cols = gold_df.select_dtypes(include=['object', 'string']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in gold_df.columns:\n",
    "            unique_count = gold_df[col].nunique()\n",
    "            print(f\"\\n  📊 {col.upper()}:\")\n",
    "            print(f\"     Unique values: {unique_count:,}\")\n",
    "            \n",
    "            # Always show value counts for categorical data\n",
    "            value_counts = gold_df[col].value_counts()\n",
    "            for value, count in value_counts.items():\n",
    "                pct = (count / len(gold_df)) * 100\n",
    "                print(f\"     {str(value):25} : {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Sample records\n",
    "    print(f\"\\n🎯 SAMPLE RECORDS (First 3):\")\n",
    "    print(gold_df.head(3).to_string())\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No gold data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Silver vs Gold Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Silver vs Gold layers\n",
    "if not silver_df.empty and not gold_df.empty:\n",
    "    print(\"🔄 SILVER vs GOLD LAYER COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Basic comparison\n",
    "    silver_wallets = silver_df['wallet_address'].nunique()\n",
    "    gold_wallets = gold_df['wallet_address'].nunique()\n",
    "    \n",
    "    print(f\"📊 RECORD COUNTS:\")\n",
    "    print(f\"  Silver Layer: {len(silver_df):,} records\")\n",
    "    print(f\"  Gold Layer:   {len(gold_df):,} records\")\n",
    "    \n",
    "    print(f\"\\n🏦 UNIQUE WALLETS:\")\n",
    "    print(f\"  Silver Layer: {silver_wallets:,} wallets\")\n",
    "    print(f\"  Gold Layer:   {gold_wallets:,} wallets\")\n",
    "    print(f\"  Filtered Out: {silver_wallets - gold_wallets:,} wallets\")\n",
    "    print(f\"  Filter Rate:  {((silver_wallets - gold_wallets)/silver_wallets*100):.1f}%\")\n",
    "    \n",
    "    # Timeframe comparison\n",
    "    if 'time_period' in silver_df.columns and 'time_period' in gold_df.columns:\n",
    "        silver_timeframes = set(silver_df['time_period'].unique())\n",
    "        gold_timeframes = set(gold_df['time_period'].unique())\n",
    "        \n",
    "        print(f\"\\n⏰ TIMEFRAME COVERAGE:\")\n",
    "        print(f\"  Silver Timeframes: {sorted(silver_timeframes)}\")\n",
    "        print(f\"  Gold Timeframes:   {sorted(gold_timeframes)}\")\n",
    "        \n",
    "        missing_in_gold = silver_timeframes - gold_timeframes\n",
    "        if missing_in_gold:\n",
    "            print(f\"  ⚠️  Missing in Gold: {sorted(missing_in_gold)}\")\n",
    "        \n",
    "        extra_in_gold = gold_timeframes - silver_timeframes\n",
    "        if extra_in_gold:\n",
    "            print(f\"  ℹ️  Extra in Gold: {sorted(extra_in_gold)}\")\n",
    "    \n",
    "    # Column comparison\n",
    "    silver_cols = set(silver_df.columns)\n",
    "    gold_cols = set(gold_df.columns)\n",
    "    \n",
    "    print(f\"\\n📋 COLUMN COMPARISON:\")\n",
    "    print(f\"  Silver Columns: {len(silver_cols)}\")\n",
    "    print(f\"  Gold Columns:   {len(gold_cols)}\")\n",
    "    \n",
    "    common_cols = silver_cols & gold_cols\n",
    "    silver_only = silver_cols - gold_cols  \n",
    "    gold_only = gold_cols - silver_cols\n",
    "    \n",
    "    print(f\"  Common:         {len(common_cols)}\")\n",
    "    print(f\"  Silver Only:    {len(silver_only)}\")\n",
    "    print(f\"  Gold Only:      {len(gold_only)}\")\n",
    "    \n",
    "    if silver_only:\n",
    "        print(f\"\\n  📊 Silver-only columns: {sorted(silver_only)}\")\n",
    "    \n",
    "    if gold_only:\n",
    "        print(f\"\\n  🥇 Gold-only columns: {sorted(gold_only)}\")\n",
    "\n",
    "elif not silver_df.empty:\n",
    "    print(\"⚠️ Only Silver data available - cannot compare with Gold\")\n",
    "elif not gold_df.empty:\n",
    "    print(\"⚠️ Only Gold data available - cannot compare with Silver\")\n",
    "else:\n",
    "    print(\"❌ No data available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary Report\n",
    "print(\"📋 SOLANA DATA PIPELINE - SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"🕐 Report Generated: {current_time}\")\n",
    "\n",
    "# Silver layer summary\n",
    "if not silver_df.empty:\n",
    "    print(f\"\\n✅ SILVER WALLET PNL LAYER:\")\n",
    "    print(f\"   📊 Records: {len(silver_df):,}\")\n",
    "    print(f\"   🏦 Unique Wallets: {silver_df['wallet_address'].nunique():,}\")\n",
    "    print(f\"   ⏰ Timeframes: {len(silver_df['time_period'].unique())}\")\n",
    "    \n",
    "    # PnL insights\n",
    "    if 'total_pnl' in silver_df.columns:\n",
    "        profitable = (silver_df['total_pnl'] > 0).sum()\n",
    "        avg_pnl = silver_df['total_pnl'].mean()\n",
    "        print(f\"   💰 Profitable Records: {profitable:,}/{len(silver_df):,} ({profitable/len(silver_df)*100:.1f}%)\")\n",
    "        print(f\"   📈 Average PnL: ${avg_pnl:.2f}\")\n",
    "    \n",
    "    # Trading activity\n",
    "    if 'trade_count' in silver_df.columns:\n",
    "        total_trades = silver_df['trade_count'].sum()\n",
    "        avg_trades = silver_df['trade_count'].mean()\n",
    "        print(f\"   🔄 Total Trades: {total_trades:,.0f}\")\n",
    "        print(f\"   📊 Avg Trades/Wallet: {avg_trades:.1f}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n❌ SILVER LAYER: No data available\")\n",
    "\n",
    "# Gold layer summary  \n",
    "if not gold_df.empty:\n",
    "    print(f\"\\n✅ GOLD SMART WALLETS LAYER:\")\n",
    "    print(f\"   📊 Records: {len(gold_df):,}\")\n",
    "    print(f\"   🏦 Unique Wallets: {gold_df['wallet_address'].nunique():,}\")\n",
    "    \n",
    "    if 'time_period' in gold_df.columns:\n",
    "        print(f\"   ⏰ Timeframes: {len(gold_df['time_period'].unique())}\")\n",
    "    \n",
    "    # Classifications\n",
    "    if 'trader_classification' in gold_df.columns:\n",
    "        classifications = gold_df['trader_classification'].value_counts()\n",
    "        print(f\"   🏆 Classifications:\")\n",
    "        for classification, count in classifications.items():\n",
    "            print(f\"      {classification}: {count:,}\")\n",
    "    \n",
    "    # Smart trader scores\n",
    "    if 'smart_trader_score' in gold_df.columns:\n",
    "        avg_score = gold_df['smart_trader_score'].mean()\n",
    "        max_score = gold_df['smart_trader_score'].max()\n",
    "        print(f\"   🎯 Avg Smart Score: {avg_score:.3f}\")\n",
    "        print(f\"   🏆 Max Smart Score: {max_score:.3f}\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n❌ GOLD LAYER: No data available\")\n",
    "\n",
    "# Pipeline effectiveness\n",
    "if not silver_df.empty and not gold_df.empty:\n",
    "    silver_wallets = silver_df['wallet_address'].nunique()\n",
    "    gold_wallets = gold_df['wallet_address'].nunique()\n",
    "    filter_rate = ((silver_wallets - gold_wallets) / silver_wallets) * 100\n",
    "    \n",
    "    print(f\"\\n🔧 PIPELINE EFFECTIVENESS:\")\n",
    "    print(f\"   📥 Input: {silver_wallets:,} wallets\")\n",
    "    print(f\"   📤 Output: {gold_wallets:,} wallets\")\n",
    "    print(f\"   🚫 Filtered: {filter_rate:.1f}%\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\n💡 RECOMMENDATIONS:\")\n",
    "\n",
    "if not silver_df.empty and 'total_pnl' in silver_df.columns:\n",
    "    profitable_pct = (silver_df['total_pnl'] > 0).sum() / len(silver_df) * 100\n",
    "    if profitable_pct == 0:\n",
    "        print(f\"   ⚠️  No profitable wallets found - review PnL calculation\")\n",
    "    elif profitable_pct < 10:\n",
    "        print(f\"   ⚠️  Very low profitability ({profitable_pct:.1f}%) - check data quality\")\n",
    "\n",
    "if not silver_df.empty and not gold_df.empty:\n",
    "    filter_rate = ((silver_df['wallet_address'].nunique() - gold_df['wallet_address'].nunique()) / \n",
    "                   silver_df['wallet_address'].nunique()) * 100\n",
    "    if filter_rate < 5:\n",
    "        print(f\"   ⚠️  Low filtering rate ({filter_rate:.1f}%) - consider tightening criteria\")\n",
    "    \n",
    "    if 'time_period' in gold_df.columns and 'time_period' in silver_df.columns:\n",
    "        if len(gold_df['time_period'].unique()) < len(silver_df['time_period'].unique()):\n",
    "            print(f\"   ⚠️  Missing timeframes in gold layer - run DBT for all periods\")\n",
    "\n",
    "print(f\"\\n🔚 Analysis Complete - Data pipeline review finished\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Test Updated Gold Criteria (DBT Logic)\nprint(\"🧪 TESTING UPDATED GOLD CRITERIA - DBT LOGIC\")\nprint(\"=\"*70)\n\n# Reconnect to test the updated criteria\nconn = duckdb.connect()\nconn.execute(\"INSTALL httpfs;\")\nconn.execute(\"LOAD httpfs;\")\nconn.execute(\"SET s3_endpoint='localhost:9000';\")\nconn.execute(\"SET s3_access_key_id='minioadmin';\")\nconn.execute(\"SET s3_secret_access_key='minioadmin123';\")\nconn.execute(\"SET s3_use_ssl=false;\")\nconn.execute(\"SET s3_url_style='path';\")\n\n# Test the exact DBT logic\nprint(\"🔍 Testing filter criteria from updated dbt model...\")\n\ntry:\n    # Apply the exact filtering logic from our updated dbt model\n    dbt_gold_test = conn.execute(\"\"\"\n    WITH silver_wallet_pnl AS (\n        SELECT *\n        FROM read_parquet('s3://solana-data/silver/wallet_pnl/**/*.parquet')\n    ),\n    \n    filtered_smart_wallets AS (\n        SELECT \n            wallet_address,\n            time_period,\n            trade_count,\n            win_rate,\n            total_pnl,\n            roi,\n            realized_pnl,\n            unrealized_pnl,\n            total_bought,\n            total_sold,\n            processed_for_gold\n        FROM silver_wallet_pnl\n        WHERE \n            -- Focus on portfolio-level records for 'all' timeframe\n            token_address = 'ALL_TOKENS' \n            AND time_period = 'all'\n            \n            -- Updated gold criteria matching smart_trader_config.py\n            AND total_pnl >= 10.0           -- MIN_TOTAL_PNL = 10.0\n            AND roi >= 1.0                  -- MIN_ROI_PERCENT = 1.0\n            AND win_rate >= 40.0            -- MIN_WIN_RATE_PERCENT = 40.0\n            AND trade_count >= 1            -- MIN_TRADE_COUNT = 1\n            AND total_pnl > 0               -- Must be profitable\n            \n            -- Only process unprocessed records\n            AND processed_for_gold = false\n    ),\n    \n    tier_classification AS (\n        SELECT \n            *,\n            -- Performance tier classification matching smart_trader_config.py\n            CASE \n                WHEN total_pnl >= 1000 AND roi >= 30 AND win_rate >= 60 AND trade_count >= 10 THEN 'elite'\n                WHEN total_pnl >= 100 AND roi >= 15 AND win_rate >= 40 AND trade_count >= 5 THEN 'strong'\n                ELSE 'promising'\n            END as performance_tier\n        FROM filtered_smart_wallets\n    )\n    \n    SELECT \n        COUNT(*) as total_qualifying,\n        COUNT(CASE WHEN performance_tier = 'elite' THEN 1 END) as elite_count,\n        COUNT(CASE WHEN performance_tier = 'strong' THEN 1 END) as strong_count,\n        COUNT(CASE WHEN performance_tier = 'promising' THEN 1 END) as promising_count,\n        AVG(total_pnl) as avg_pnl,\n        AVG(roi) as avg_roi,\n        AVG(win_rate) as avg_win_rate,\n        AVG(trade_count) as avg_trades\n    FROM tier_classification\n    \"\"\").fetchone()\n    \n    if dbt_gold_test:\n        total, elite, strong, promising, avg_pnl, avg_roi, avg_win_rate, avg_trades = dbt_gold_test\n        \n        print(f\"\\n✅ DBT FILTER TEST RESULTS:\")\n        print(f\"   📊 Total Qualifying: {total}\")\n        print(f\"   🏆 Elite Tier: {elite}\")\n        print(f\"   💪 Strong Tier: {strong}\")  \n        print(f\"   🌟 Promising Tier: {promising}\")\n        print(f\"   💰 Average PnL: ${avg_pnl:.2f}\")\n        print(f\"   📈 Average ROI: {avg_roi:.2f}%\")\n        print(f\"   🎯 Average Win Rate: {avg_win_rate:.1f}%\")\n        print(f\"   🔄 Average Trades: {avg_trades:.1f}\")\n        \n        if total > 0:\n            print(f\"\\n🎉 SUCCESS: Found {total} qualifying candidates!\")\n            \n            # Get sample records\n            sample_records = conn.execute(\"\"\"\n            WITH silver_wallet_pnl AS (\n                SELECT *\n                FROM read_parquet('s3://solana-data/silver/wallet_pnl/**/*.parquet')\n            ),\n            \n            filtered_smart_wallets AS (\n                SELECT \n                    wallet_address,\n                    time_period,\n                    trade_count,\n                    win_rate,\n                    total_pnl,\n                    roi,\n                    realized_pnl,\n                    unrealized_pnl,\n                    total_bought,\n                    total_sold,\n                    processed_for_gold\n                FROM silver_wallet_pnl\n                WHERE \n                    token_address = 'ALL_TOKENS' \n                    AND time_period = 'all'\n                    AND total_pnl >= 10.0\n                    AND roi >= 1.0\n                    AND win_rate >= 40.0\n                    AND trade_count >= 1\n                    AND total_pnl > 0\n                    AND processed_for_gold = false\n            )\n            \n            SELECT \n                wallet_address,\n                total_pnl,\n                roi,\n                win_rate,\n                trade_count,\n                CASE \n                    WHEN total_pnl >= 1000 AND roi >= 30 AND win_rate >= 60 AND trade_count >= 10 THEN 'elite'\n                    WHEN total_pnl >= 100 AND roi >= 15 AND win_rate >= 40 AND trade_count >= 5 THEN 'strong'\n                    ELSE 'promising'\n                END as performance_tier\n            FROM filtered_smart_wallets\n            ORDER BY total_pnl DESC\n            LIMIT 5\n            \"\"\").fetchall()\n            \n            print(f\"\\n🔝 TOP 5 QUALIFYING CANDIDATES:\")\n            for i, (wallet, pnl, roi, win_rate, trades, tier) in enumerate(sample_records):\n                print(f\"   {i+1}. {wallet[:10]}... | PnL: ${pnl:.2f} | ROI: {roi:.2f}% | Win: {win_rate:.1f}% | Trades: {trades} | Tier: {tier.upper()}\")\n        \n        else:\n            print(f\"\\n❌ NO QUALIFYING CANDIDATES\")\n            print(f\"   The updated criteria are too strict or there's no unprocessed data\")\n            \n            # Debug: check without processed_for_gold filter\n            debug_test = conn.execute(\"\"\"\n            SELECT COUNT(*) as total_without_filter\n            FROM read_parquet('s3://solana-data/silver/wallet_pnl/**/*.parquet')\n            WHERE \n                token_address = 'ALL_TOKENS' \n                AND time_period = 'all'\n                AND total_pnl >= 10.0\n                AND roi >= 1.0\n                AND win_rate >= 40.0\n                AND trade_count >= 1\n                AND total_pnl > 0\n            \"\"\").fetchone()\n            \n            if debug_test:\n                total_without_filter = debug_test[0]\n                print(f\"   💡 Debug: {total_without_filter} candidates WITHOUT processed_for_gold filter\")\n                if total_without_filter > 0:\n                    print(f\"   ➡️  Recommendation: Reset processed_for_gold flags or ignore this filter\")\n    \nexcept Exception as e:\n    print(f\"❌ Error testing DBT logic: {e}\")\n\nprint(f\"\\n✅ DBT Logic Test Complete\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}